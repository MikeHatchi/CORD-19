{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID-19 Open Research Dataset Challenge (CORD-19)\n",
    "An AI challenge with AI2, CZI, MSR, Georgetown, NIH & The White House\n",
    "\n",
    "### Task: What do we know about COVID-19 risk factors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information about the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Metadata for papers from these sources are combined: CZI, PMC, BioRxiv/MedRxiv. (total records 29500)\n",
    "\t- CZI 1236 records\n",
    "\t- PMC 27337\n",
    "\t- bioRxiv 566\n",
    "\t- medRxiv 361\n",
    "(2) 17K of the paper records have PDFs and the hash of the PDFs are in 'sha'<br>\n",
    "(3) For PMC sourced papers, one paper's metadata can be associated with one or more PDFs/shas under that paper - a PDF/sha correponding to the main article, and possibly additional PDF/shas corresponding to supporting materials for the article.<br>\n",
    "(4)\t13K of the PDFs were processed with fulltext ('has_full_text'=True)<br>\n",
    "(5) Various 'keys' are populated with the metadata:\n",
    "\t- 'pmcid': populated for all PMC paper records (27337 non null)\n",
    "\t- 'doi': populated for all BioRxiv/MedRxiv paper records and most of the other records (26357 non null)\n",
    "\t- 'WHO #Covidence': populated for all CZI records and none of the other records (1236 non null)\n",
    "\t- 'pubmed_id': populated for some of the records\n",
    "\t- 'Microsoft Academic Paper ID': populated for some of the records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chan Zuckerberg Initiative (CZI)**<br>\n",
    "**PubMed Central (PMC)** is a free digital repository that archives publicly accessible full-text scholarly articles that have been published within the biomedical and life sciences journal literature.<br>\n",
    "**BioRxiv** (pronounced \"bio-archive\") is an open access preprint repository for the biological sciences<br>\n",
    "**medRxiv. medRxiv** (pronounced med archive) is a preprint service for the medicine and health sciences and provides a free online platform for researchers to share, comment, and receive feedback on their work. Information among scientists spreads slowly, and often incompletely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sha</th>\n",
       "      <th>source_x</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>pmcid</th>\n",
       "      <th>pubmed_id</th>\n",
       "      <th>license</th>\n",
       "      <th>abstract</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal</th>\n",
       "      <th>Microsoft Academic Paper ID</th>\n",
       "      <th>WHO #Covidence</th>\n",
       "      <th>has_full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c630ebcdf30652f0422c3ec12a00b50241dc9bd9</td>\n",
       "      <td>CZI</td>\n",
       "      <td>Angiotensin-converting enzyme 2 (ACE2) as a SA...</td>\n",
       "      <td>10.1007/s00134-020-05985-9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32125455.0</td>\n",
       "      <td>cc-by-nc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>Zhang, Haibo; Penninger, Josef M.; Li, Yimin; ...</td>\n",
       "      <td>Intensive Care Med</td>\n",
       "      <td>2.002765e+09</td>\n",
       "      <td>#3252</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53eccda7977a31e3d0f565c884da036b1e85438e</td>\n",
       "      <td>CZI</td>\n",
       "      <td>Comparative genetic analysis of the novel coro...</td>\n",
       "      <td>10.1038/s41421-020-0147-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cc-by</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>Cao, Yanan; Li, Lin; Feng, Zhimin; Wan, Shengq...</td>\n",
       "      <td>Cell Discovery</td>\n",
       "      <td>3.003431e+09</td>\n",
       "      <td>#1861</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>210a892deb1c61577f6fba58505fd65356ce6636</td>\n",
       "      <td>CZI</td>\n",
       "      <td>Incubation Period and Other Epidemiological Ch...</td>\n",
       "      <td>10.3390/jcm9020538</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cc-by</td>\n",
       "      <td>The geographic spread of 2019 novel coronaviru...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Linton, M. Natalie; Kobayashi, Tetsuro; Yang, ...</td>\n",
       "      <td>Journal of Clinical Medicine</td>\n",
       "      <td>3.006065e+09</td>\n",
       "      <td>#1043</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e3b40cc8e0e137c416b4a2273a4dca94ae8178cc</td>\n",
       "      <td>CZI</td>\n",
       "      <td>Characteristics of and Public Health Responses...</td>\n",
       "      <td>10.3390/jcm9020575</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32093211.0</td>\n",
       "      <td>cc-by</td>\n",
       "      <td>In December 2019, cases of unidentified pneumo...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Deng, Sheng-Qun; Peng, Hong-Juan</td>\n",
       "      <td>J Clin Med</td>\n",
       "      <td>1.776631e+08</td>\n",
       "      <td>#1999</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92c2c9839304b4f2bc1276d41b1aa885d8b364fd</td>\n",
       "      <td>CZI</td>\n",
       "      <td>Imaging changes in severe COVID-19 pneumonia</td>\n",
       "      <td>10.1007/s00134-020-05976-w</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32125453.0</td>\n",
       "      <td>cc-by-nc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>Zhang, Wei</td>\n",
       "      <td>Intensive Care Med</td>\n",
       "      <td>3.006643e+09</td>\n",
       "      <td>#3242</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        sha source_x  \\\n",
       "0  c630ebcdf30652f0422c3ec12a00b50241dc9bd9      CZI   \n",
       "1  53eccda7977a31e3d0f565c884da036b1e85438e      CZI   \n",
       "2  210a892deb1c61577f6fba58505fd65356ce6636      CZI   \n",
       "3  e3b40cc8e0e137c416b4a2273a4dca94ae8178cc      CZI   \n",
       "4  92c2c9839304b4f2bc1276d41b1aa885d8b364fd      CZI   \n",
       "\n",
       "                                               title  \\\n",
       "0  Angiotensin-converting enzyme 2 (ACE2) as a SA...   \n",
       "1  Comparative genetic analysis of the novel coro...   \n",
       "2  Incubation Period and Other Epidemiological Ch...   \n",
       "3  Characteristics of and Public Health Responses...   \n",
       "4       Imaging changes in severe COVID-19 pneumonia   \n",
       "\n",
       "                          doi pmcid   pubmed_id   license  \\\n",
       "0  10.1007/s00134-020-05985-9   NaN  32125455.0  cc-by-nc   \n",
       "1   10.1038/s41421-020-0147-1   NaN         NaN     cc-by   \n",
       "2          10.3390/jcm9020538   NaN         NaN     cc-by   \n",
       "3          10.3390/jcm9020575   NaN  32093211.0     cc-by   \n",
       "4  10.1007/s00134-020-05976-w   NaN  32125453.0  cc-by-nc   \n",
       "\n",
       "                                            abstract publish_time  \\\n",
       "0                                                NaN         2020   \n",
       "1                                                NaN         2020   \n",
       "2  The geographic spread of 2019 novel coronaviru...         2020   \n",
       "3  In December 2019, cases of unidentified pneumo...         2020   \n",
       "4                                                NaN         2020   \n",
       "\n",
       "                                             authors  \\\n",
       "0  Zhang, Haibo; Penninger, Josef M.; Li, Yimin; ...   \n",
       "1  Cao, Yanan; Li, Lin; Feng, Zhimin; Wan, Shengq...   \n",
       "2  Linton, M. Natalie; Kobayashi, Tetsuro; Yang, ...   \n",
       "3                   Deng, Sheng-Qun; Peng, Hong-Juan   \n",
       "4                                         Zhang, Wei   \n",
       "\n",
       "                        journal  Microsoft Academic Paper ID WHO #Covidence  \\\n",
       "0            Intensive Care Med                 2.002765e+09          #3252   \n",
       "1                Cell Discovery                 3.003431e+09          #1861   \n",
       "2  Journal of Clinical Medicine                 3.006065e+09          #1043   \n",
       "3                    J Clin Med                 1.776631e+08          #1999   \n",
       "4            Intensive Care Med                 3.006643e+09          #3242   \n",
       "\n",
       "  has_full_text  \n",
       "0          True  \n",
       "1          True  \n",
       "2          True  \n",
       "3          True  \n",
       "4         False  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"2020-03-13/all_sources_metadata_2020-03-13.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29500, 14)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# gathering only the non-numerical type\\ncat_col = [cat for cat in data.dtypes.index if data.dtypes[cat]=='object']\\n\\n# printing the frequencies for each category\\nfor col in cat_col:\\n    print('\\nFrequency of categories within {}'.format(col))\\n    print(data[col].value_counts())\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# gathering only the non-numerical type\n",
    "cat_col = [cat for cat in data.dtypes.index if data.dtypes[cat]=='object']\n",
    "\n",
    "# printing the frequencies for each category\n",
    "for col in cat_col:\n",
    "    print('\\nFrequency of categories within {}'.format(col))\n",
    "    print(data[col].value_counts())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Load the dataset from the CSV and save it to 'data_text'\n",
    "'''\n",
    "import pandas as pd\n",
    "data = pd.read_csv('2020-03-13/all_sources_metadata_2020-03-13.csv', error_bad_lines=False);\n",
    "# We only need the Headlines text column from the data\n",
    "data_text = data[:300000][['title']];\n",
    "data_text['index'] = data_text.index\n",
    "\n",
    "documents = data_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29500\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Get the total number of documents\n",
    "'''\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "Tokenization (split text into sentence into words) / Words < 3 characters out / Stopwords removed / lemmatize (third pers. & past to present verb) / stemmed (word reduced to its root form)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Loading Gensim and nltk libraries\n",
    "'''\n",
    "# pip install gensim\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/mikehatchi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Write a function to perform the pre processing steps on the entire dataset\n",
    "'''\n",
    "def lemmatize_stemming(text):\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "# Tokenize and lemmatize\n",
    "def preprocess(text):\n",
    "    result=[]\n",
    "    for token in gensim.utils.simple_preprocess(text) :\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            # TODO: Apply lemmatize_stemming on the token, then add to the results list\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original document: \n",
      "['Angiotensin-converting', 'enzyme', '2', '(ACE2)', 'as', 'a', 'SARS-CoV-2', 'receptor:', 'molecular', 'mechanisms', 'and', 'potential', 'therapeutic', 'target']\n",
      "\n",
      "\n",
      "Tokenized and lemmatized document: \n",
      "['angiotensin', 'convert', 'enzym', 'sar', 'receptor', 'molecular', 'mechan', 'potenti', 'therapeut', 'target']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Preview a document after preprocessing\n",
    "'''\n",
    "document_num = 0\n",
    "doc_sample = documents[documents['index'] == document_num].values[0][0]\n",
    "\n",
    "print(\"Original document: \")\n",
    "words = []\n",
    "for word in doc_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print(\"\\n\\nTokenized and lemmatized document: \")\n",
    "print(preprocess(doc_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = documents.dropna(subset=['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = documents['title'].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [angiotensin, convert, enzym, sar, receptor, m...\n",
       "1     [compar, genet, analysi, novel, coronavirus, n...\n",
       "2     [incub, period, epidemiolog, characterist, nov...\n",
       "3     [characterist, public, health, respons, corona...\n",
       "4                [imag, chang, sever, covid, pneumonia]\n",
       "5     [updat, estim, risk, transmiss, novel, coronav...\n",
       "6     [real, time, forecast, ncov, epidem, china, fe...\n",
       "7     [retract, chines, medic, staff, request, inter...\n",
       "8     [covid, outbreak, diamond, princess, cruis, sh...\n",
       "9     [distinct, role, sialosid, protein, receptor, ...\n",
       "10    [month, coronavirus, diseas, covid, epidem, ch...\n",
       "11    [effect, airport, screen, detect, travel, infe...\n",
       "12    [genom, detect, coronavirus, type, tool, rapid...\n",
       "13    [case, index, patient, caus, tertiari, transmi...\n",
       "14    [emerg, novel, coronavirus, ncov, need, rapid,...\n",
       "15               [coronavirus, ncov, epidem, hindsight]\n",
       "16    [nonstructur, protein, like, associ, evolut, n...\n",
       "17    [pathogen, ncov, quick, overview, comparison, ...\n",
       "18    [remdesivir, chloroquin, effect, inhibit, rece...\n",
       "19    [potenti, global, spread, novel, coronavirus, ...\n",
       "20    [sever, acut, respiratori, symptom, suspect, sar]\n",
       "21    [statist, base, predict, coronavirus, epidem, ...\n",
       "22    [earli, transmiss, pattern, coronavirus, disea...\n",
       "23    [hrct, imag, featur, repres, import, case, nov...\n",
       "24    [comprehens, genom, analysi, lncrnas, cell, po...\n",
       "25    [potenti, factor, influenc, repeat, sar, outbr...\n",
       "26    [puzzl, high, pathogen, human, coronavirus, ncov]\n",
       "27    [retract, retract, chines, medic, staff, reque...\n",
       "28    [critic, care, respons, hospit, outbreak, ncov...\n",
       "29    [effect, respons, covid, mer, outbreak, contai...\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of words on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 angiotensin\n",
      "1 convert\n",
      "2 enzym\n",
      "3 mechan\n",
      "4 molecular\n",
      "5 potenti\n",
      "6 receptor\n",
      "7 sar\n",
      "8 target\n",
      "9 therapeut\n",
      "10 analysi\n",
      "11 compar\n",
      "12 coronavirus\n",
      "13 differ\n",
      "14 genet\n",
      "15 ncov\n",
      "16 novel\n",
      "17 popul\n",
      "18 avail\n",
      "19 case\n",
      "20 characterist\n",
      "21 data\n",
      "22 epidemiolog\n",
      "23 incub\n",
      "24 infect\n",
      "25 period\n",
      "26 public\n",
      "27 right\n",
      "28 statist\n",
      "29 truncat\n",
      "30 china\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 30:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "c19",
   "language": "python",
   "name": "c19"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
